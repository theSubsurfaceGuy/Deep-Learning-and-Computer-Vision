{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fault.ipynb",
      "provenance": [],
      "mount_file_id": "1vzMki2KYKGgenEGR7-usjU9Ost_QODLC",
      "authorship_tag": "ABX9TyOwZvCdybMiyTqmr8RYsWQd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWtp-Xa5XKfO"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(12345)\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(seed)\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard\n",
        "from keras import backend as keras\n",
        "from utils import DataGenerator\n",
        "from unet3 import *\n",
        "\n",
        "def main():\n",
        "  goTrain()\n",
        "\n",
        "def goTrain():\n",
        "  # input image dimensions\n",
        "  params = {'batch_size':1,\n",
        "          'dim':(128,128,128),\n",
        "          'n_channels':1,\n",
        "          'shuffle': True}\n",
        "  seismPathT = \"/content/drive/My Drive/data_Wu/train/seis\"\n",
        "  faultPathT = \"/content/train fault/fault\"\n",
        "\n",
        "  seismPathV = \"/content/drive/My Drive/data_Wu/validation/seis\"\n",
        "  faultPathV = \"/content/drive/My Drive/data_Wu/validation/fault\"\n",
        "  train_ID = range(200)\n",
        "  valid_ID = range(20)\n",
        "  train_generator = DataGenerator(dpath=seismPathT,fpath=faultPathT,\n",
        "                                  data_IDs=train_ID,**params)\n",
        "  valid_generator = DataGenerator(dpath=seismPathV,fpath=faultPathV,\n",
        "                                  data_IDs=valid_ID,**params)\n",
        "  model = unet(input_size=(None, None, None,1))\n",
        "  model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  # checkpoint\n",
        "  filepath=\"check1/fseg-{epoch:02d}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_acc', \n",
        "        verbose=1, save_best_only=False, mode='max')\n",
        "  logging = TrainValTensorBoard()\n",
        "  #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \n",
        "  #                              patience=20, min_lr=1e-8)\n",
        "  callbacks_list = [checkpoint, logging]\n",
        "  print(\"data prepared, ready to train!\")\n",
        "  # Fit the model\n",
        "  history=model.fit_generator(generator=train_generator,\n",
        "  validation_data=valid_generator,epochs=100,callbacks=callbacks_list,verbose=1)\n",
        "  model.save('check1/fseg.hdf5')\n",
        "  showHistory(history)\n",
        "\n",
        "def showHistory(history):\n",
        "  # list all data in history\n",
        "  print(history.history.keys())\n",
        "  fig = plt.figure(figsize=(10,6))\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('Model accuracy',fontsize=20)\n",
        "  plt.ylabel('Accuracy',fontsize=20)\n",
        "  plt.xlabel('Epoch',fontsize=20)\n",
        "  plt.legend(['train', 'test'], loc='center right',fontsize=20)\n",
        "  plt.tick_params(axis='both', which='major', labelsize=18)\n",
        "  plt.tick_params(axis='both', which='minor', labelsize=18)\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for loss\n",
        "  fig = plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss',fontsize=20)\n",
        "  plt.ylabel('Loss',fontsize=20)\n",
        "  plt.xlabel('Epoch',fontsize=20)\n",
        "  plt.legend(['train', 'test'], loc='center right',fontsize=20)\n",
        "  plt.tick_params(axis='both', which='major', labelsize=18)\n",
        "  plt.tick_params(axis='both', which='minor', labelsize=18)\n",
        "  plt.show()\n",
        "\n",
        "class TrainValTensorBoard(TensorBoard):\n",
        "    def __init__(self, log_dir='./log1', **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "        training_log_dir = os.path.join(log_dir, 'training')\n",
        "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TrainValTensorBoard, self).set_model(model)\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "        for name, value in val_logs.items():\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        logs.update({'lr': keras.eval(self.model.optimizer.lr)})\n",
        "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
        "        self.val_writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}